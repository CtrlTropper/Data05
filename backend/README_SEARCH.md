# Search Module - H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng

Module t√¨m ki·∫øm vector b·∫±ng FAISS v·ªõi c√°c t√≠nh nƒÉng t√¨m ki·∫øm context v√† filter theo document.

## üéØ **T√çNH NƒÇNG CH√çNH**

### **1. T√¨m ki·∫øm c∆° b·∫£n**
- ‚úÖ `search(query, top_k=5, doc_id=None)` - T√¨m ki·∫øm vector
- ‚úÖ H·ªó tr·ª£ filter theo document ID
- ‚úÖ Tr·∫£ v·ªÅ danh s√°ch context (ƒëo·∫°n text g·∫ßn nh·∫•t)
- ‚úÖ Cosine similarity v·ªõi FAISS IndexFlatIP

### **2. C√°c lo·∫°i t√¨m ki·∫øm**
- ‚úÖ **Text Search**: T√¨m ki·∫øm b·∫±ng text query
- ‚úÖ **Vector Search**: T√¨m ki·∫øm b·∫±ng vector
- ‚úÖ **Document Filter**: T√¨m ki·∫øm trong document c·ª• th·ªÉ
- ‚úÖ **Similar Contexts**: T√¨m contexts t∆∞∆°ng t·ª±

## üìö **API ENDPOINTS**

### **1. Text Search**
```http
POST /api/search/text
Content-Type: application/json

{
    "query": "tr√≠ tu·ªá nh√¢n t·∫°o v√† machine learning",
    "top_k": 5,
    "doc_id": "document_uuid"  // optional
}
```

**Response:**
```json
{
    "query": "tr√≠ tu·ªá nh√¢n t·∫°o v√† machine learning",
    "results": [
        {
            "content": "Machine learning l√† m·ªôt ph·∫ßn c·ªßa tr√≠ tu·ªá nh√¢n t·∫°o",
            "similarity_score": 0.95,
            "document_id": "doc_uuid",
            "chunk_id": "doc_uuid_chunk_1",
            "chunk_index": 1,
            "filename": "document.txt",
            "content_length": 45,
            "created_at": "2024-01-01T10:00:00"
        }
    ],
    "total_found": 1,
    "search_time": 0.123
}
```

### **2. Vector Search**
```http
POST /api/search/vector
Content-Type: application/json

{
    "vector": [0.1, 0.2, 0.3, ...],  // 1024 dimensions
    "top_k": 5,
    "doc_id": "document_uuid"  // optional
}
```

### **3. Document Contexts**
```http
GET /api/search/document/{document_id}
```

### **4. Similar Contexts**
```http
POST /api/search/similar
Content-Type: application/json

{
    "query": "neural networks v√† deep learning",
    "top_k": 3
}
```

### **5. Embed and Search**
```http
POST /api/search/embed
Content-Type: application/json

{
    "query": "computer vision",
    "top_k": 5
}
```

## üîß **S·ª¨ D·ª§NG TRONG CODE**

### **1. T√¨m ki·∫øm c∆° b·∫£n**
```python
from db.faiss_store import faiss_store
from services.embedding_service import embedding_service

# T√¨m ki·∫øm b·∫±ng text
results = faiss_store.search_text(
    query_text="tr√≠ tu·ªá nh√¢n t·∫°o",
    top_k=5,
    embedding_service=embedding_service
)

# T√¨m ki·∫øm trong document c·ª• th·ªÉ
results = faiss_store.search_text(
    query_text="machine learning",
    top_k=3,
    doc_id="document_uuid",
    embedding_service=embedding_service
)
```

### **2. T√¨m ki·∫øm b·∫±ng vector**
```python
import numpy as np

# T·∫°o embedding
embedding = embedding_service.generate_embedding("AI technology")
query_vector = np.array(embedding, dtype=np.float32)

# T√¨m ki·∫øm
results = faiss_store.search_with_context(
    query_vector=query_vector,
    top_k=5,
    doc_id="document_uuid"  # optional
)
```

### **3. L·∫•y contexts c·ªßa document**
```python
# L·∫•y t·∫•t c·∫£ contexts c·ªßa m·ªôt document
contexts = faiss_store.get_contexts_by_document("document_uuid")

for context in contexts:
    print(f"Chunk {context['chunk_index']}: {context['content']}")
```

### **4. T√¨m contexts t∆∞∆°ng t·ª±**
```python
# T√¨m contexts t∆∞∆°ng t·ª± v·ªõi m·ªôt ƒëo·∫°n text
results = faiss_store.search_similar_contexts(
    context_text="deep learning v√† neural networks",
    top_k=3,
    embedding_service=embedding_service
)
```

## üöÄ **C√ÅCH S·ª¨ D·ª§NG**

### **1. Test Search Functionality**
```bash
# Ch·∫°y test script
python test_search.py
```

### **2. API Testing**
```bash
# Text search
curl -X POST "http://localhost:8000/api/search/text" \
  -H "Content-Type: application/json" \
  -d '{"query": "tr√≠ tu·ªá nh√¢n t·∫°o", "top_k": 5}'

# Search in specific document
curl -X POST "http://localhost:8000/api/search/text" \
  -H "Content-Type: application/json" \
  -d '{"query": "machine learning", "top_k": 3, "doc_id": "document_uuid"}'

# Get document contexts
curl "http://localhost:8000/api/search/document/document_uuid"

# Search stats
curl "http://localhost:8000/api/search/stats"
```

## üìä **C·∫§U TR√öC D·ªÆ LI·ªÜU**

### **Search Result Format**
```json
{
    "content": "N·ªôi dung ƒëo·∫°n text",
    "similarity_score": 0.95,
    "document_id": "doc_uuid",
    "chunk_id": "doc_uuid_chunk_1",
    "chunk_index": 1,
    "filename": "document.txt",
    "content_length": 45,
    "created_at": "2024-01-01T10:00:00"
}
```

### **Search Response Format**
```json
{
    "query": "search query",
    "results": [...],
    "total_found": 5,
    "search_time": 0.123
}
```

## ‚ö° **PERFORMANCE**

### **T·ªëi ∆∞u h√≥a**
- ‚úÖ **Batch Search**: T√¨m ki·∫øm nhi·ªÅu vectors c√πng l√∫c
- ‚úÖ **Document Filter**: Filter hi·ªáu qu·∫£ theo document_id
- ‚úÖ **Vector Normalization**: Cosine similarity v·ªõi FAISS
- ‚úÖ **Memory Efficient**: Ch·ªâ load metadata c·∫ßn thi·∫øt

### **Benchmarks**
- **Text Search**: ~100-200ms (bao g·ªìm embedding generation)
- **Vector Search**: ~10-50ms (ch·ªâ FAISS search)
- **Document Filter**: ~20-100ms (t√πy s·ªë l∆∞·ª£ng vectors)

## üîç **T√åM KI·∫æM N√ÇNG CAO**

### **1. Multi-document Search**
```python
# T√¨m ki·∫øm trong nhi·ªÅu documents
doc_ids = ["doc1", "doc2", "doc3"]
all_results = []

for doc_id in doc_ids:
    results = faiss_store.search_text(
        query_text="AI technology",
        top_k=3,
        doc_id=doc_id,
        embedding_service=embedding_service
    )
    all_results.extend(results)

# Sort by similarity score
all_results.sort(key=lambda x: x['similarity_score'], reverse=True)
```

### **2. Context Aggregation**
```python
# T·ªïng h·ª£p contexts t·ª´ nhi·ªÅu chunks
def aggregate_contexts(results, max_length=2000):
    aggregated = ""
    for result in results:
        if len(aggregated) + len(result['content']) <= max_length:
            aggregated += result['content'] + "\n\n"
        else:
            break
    return aggregated.strip()
```

### **3. Similarity Threshold**
```python
# Filter theo similarity threshold
def filter_by_threshold(results, threshold=0.7):
    return [r for r in results if r['similarity_score'] >= threshold]
```

## üêõ **TROUBLESHOOTING**

### **1. Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£**
```bash
# Ki·ªÉm tra FAISS index
curl "http://localhost:8000/api/search/stats"

# Ki·ªÉm tra documents
curl "http://localhost:8000/api/documents"
```

### **2. Search ch·∫≠m**
```bash
# Ki·ªÉm tra embedding service
curl "http://localhost:8000/api/embed/stats"

# Restart service
python main.py
```

### **3. Vector dimension l·ªói**
```python
# Ki·ªÉm tra embedding dimension
embedding = embedding_service.generate_embedding("test")
print(f"Dimension: {len(embedding)}")  # Should be 1024
```

## üìù **NOTES**

- **Vector Dimension**: 1024 (multilingual-e5-large)
- **Similarity Metric**: Cosine similarity
- **Index Type**: FAISS IndexFlatIP
- **Document Filter**: H·ªó tr·ª£ filter theo document_id
- **Context Format**: Tr·∫£ v·ªÅ ƒë·∫ßy ƒë·ªß metadata
- **Performance**: T·ªëi ∆∞u cho search nhanh
- **Offline**: Ho√†n to√†n offline, kh√¥ng c·∫ßn internet
