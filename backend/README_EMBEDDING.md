# Embedding Module - HÆ°á»›ng dáº«n sá»­ dá»¥ng

Module xá»­ lÃ½ embedding offline cho há»‡ thá»‘ng chatbot RAG + LLM.

## ğŸ—ï¸ Cáº¥u trÃºc Module

```
backend/
â”œâ”€â”€ services/
â”‚   â””â”€â”€ embedding_service.py    # Service xá»­ lÃ½ embedding
â”œâ”€â”€ db/
â”‚   â””â”€â”€ faiss_store.py         # FAISS vector store
â”œâ”€â”€ routers/
â”‚   â””â”€â”€ embedding.py           # API endpoints
â””â”€â”€ models/
    â””â”€â”€ embedding/             # ThÆ° má»¥c chá»©a model
```

## ğŸš€ CÃ i Ä‘áº·t Model

### 1. Táº£i model multilingual-e5-large

```bash
# Táº¡o thÆ° má»¥c
mkdir -p models/embedding

# Táº£i model (cáº§n cÃ³ internet láº§n Ä‘áº§u)
python -c "
from sentence_transformers import SentenceTransformer
model = SentenceTransformer('intfloat/multilingual-e5-large')
model.save('models/embedding')
print('Model downloaded successfully!')
"
```

### 2. Kiá»ƒm tra model

```bash
# Kiá»ƒm tra thÆ° má»¥c model
ls -la models/embedding/
# NÃªn cÃ³ cÃ¡c file: config.json, pytorch_model.bin, tokenizer.json, etc.
```

## ğŸ“š API Endpoints

### 1. Embed Document
```http
POST /api/embed/document/{document_id}
Content-Type: application/json

{
    "chunk_size": 500,
    "chunk_overlap": 50
}
```

**Response:**
```json
{
    "document_id": "uuid",
    "chunks_created": 25,
    "vectors_stored": 25,
    "processing_time": 12.5,
    "status": "success"
}
```

### 2. Embed Text
```http
POST /api/embed/text
Content-Type: application/json

{
    "text": "ÄÃ¢y lÃ  Ä‘oáº¡n vÄƒn báº£n cáº§n táº¡o embedding"
}
```

**Response:**
```json
{
    "embedding": [0.1, 0.2, 0.3, ...],
    "dimension": 1024,
    "text_length": 45
}
```

### 3. Get Embedding Stats
```http
GET /api/embed/stats
```

**Response:**
```json
{
    "faiss_store": {
        "total_vectors": 150,
        "dimension": 1024,
        "documents_count": 5,
        "index_size_mb": 0.6
    },
    "embedding_service": {
        "model_loaded": true,
        "model_path": "models/embedding",
        "device": "cpu",
        "dimension": 1024
    },
    "documents": {
        "total_documents": 5,
        "processed_documents": 3
    }
}
```

### 4. Delete Document Embeddings
```http
DELETE /api/embed/document/{document_id}
```

### 5. Get Document Vectors
```http
GET /api/embed/document/{document_id}/vectors
```

## ğŸ”§ Sá»­ dá»¥ng trong Code

### 1. Generate Embedding

```python
from services.embedding_service import embedding_service

# Táº¡o embedding cho text
text = "ÄÃ¢y lÃ  Ä‘oáº¡n vÄƒn báº£n"
embedding = embedding_service.generate_embedding(text)
print(f"Embedding dimension: {len(embedding)}")
```

### 2. Batch Embeddings

```python
texts = ["Text 1", "Text 2", "Text 3"]
embeddings = embedding_service.generate_embeddings_batch(texts)
print(f"Generated {len(embeddings)} embeddings")
```

### 3. FAISS Operations

```python
from db.faiss_store import faiss_store
import numpy as np

# ThÃªm vectors
vectors = np.array(embeddings, dtype=np.float32)
metadata = [{"document_id": "doc1", "content": "text1"}]
vector_ids = faiss_store.add_vectors(vectors, metadata)

# TÃ¬m kiáº¿m
query_vector = np.array([embedding], dtype=np.float32)
results = faiss_store.search(query_vector, k=5)
```

## ğŸ“Š Workflow Xá»­ lÃ½ Document

### 1. Upload Document
```bash
curl -X POST "http://localhost:8000/api/documents/upload" \
  -F "file=@document.txt"
```

### 2. Create Embeddings
```bash
curl -X POST "http://localhost:8000/api/embed/document/{document_id}" \
  -H "Content-Type: application/json" \
  -d '{"chunk_size": 500, "chunk_overlap": 50}'
```

### 3. Check Stats
```bash
curl "http://localhost:8000/api/embed/stats"
```

## ğŸ—‚ï¸ Cáº¥u trÃºc Dá»¯ liá»‡u

### FAISS Store
- **Index**: `data/faiss_store/faiss_index.bin`
- **Metadata**: `data/faiss_store/metadata.json`

### Metadata Format
```json
{
    "vector_id": "vec_0_abc123",
    "document_id": "doc_uuid",
    "chunk_id": "doc_uuid_chunk_0",
    "chunk_index": 0,
    "content": "Ná»™i dung chunk...",
    "content_length": 500,
    "created_at": "2024-01-01T10:00:00",
    "filename": "document.txt",
    "index_id": 0
}
```

## âš¡ Performance Tips

### 1. Batch Processing
- Sá»­ dá»¥ng `generate_embeddings_batch()` cho nhiá»u text
- Xá»­ lÃ½ documents theo batch

### 2. Memory Management
- Model Ä‘Æ°á»£c load má»™t láº§n vÃ  reuse
- FAISS index Ä‘Æ°á»£c cache trÃªn disk
- GPU memory Ä‘Æ°á»£c cleanup khi shutdown

### 3. Chunking Strategy
- Chunk size: 500-1000 characters
- Overlap: 50-100 characters
- TÃ¬m Ä‘iá»ƒm cáº¯t tá»± nhiÃªn (dáº¥u cÃ¢u, xuá»‘ng dÃ²ng)

## ğŸ› Troubleshooting

### 1. Model khÃ´ng load Ä‘Æ°á»£c
```bash
# Kiá»ƒm tra thÆ° má»¥c model
ls -la models/embedding/

# Kiá»ƒm tra logs
tail -f logs/app.log
```

### 2. FAISS index lá»—i
```bash
# XÃ³a vÃ  táº¡o láº¡i index
rm -rf data/faiss_store/
mkdir -p data/faiss_store/
```

### 3. Memory issues
```bash
# Kiá»ƒm tra RAM usage
htop

# Restart service
python main.py
```

## ğŸ“ Notes

- Model multilingual-e5-large cÃ³ dimension 1024
- FAISS sá»­ dá»¥ng cosine similarity (IndexFlatIP)
- Táº¥t cáº£ operations Ä‘á»u offline
- Metadata Ä‘Æ°á»£c lÆ°u dÆ°á»›i dáº¡ng JSON
- Há»— trá»£ batch processing cho performance tá»‘t hÆ¡n
