"""
Setup script ƒë·ªÉ t·∫£i models
Script t·∫£i c√°c AI models c·∫ßn thi·∫øt cho h·ªá th·ªëng
"""

import os
import sys
from pathlib import Path
import subprocess

def download_embedding_model():
    """T·∫£i embedding model"""
    print("üì• Downloading embedding model (intfloat/multilingual-e5-large)...")
    
    model_path = Path("models/embedding")
    model_path.mkdir(parents=True, exist_ok=True)
    
    try:
        # T·∫£i model b·∫±ng sentence-transformers
        script = """
from sentence_transformers import SentenceTransformer
import os

print("Downloading multilingual-e5-large...")
model = SentenceTransformer('intfloat/multilingual-e5-large')
model.save('models/embedding')
print("‚úÖ Embedding model downloaded successfully!")
"""
        
        with open("temp_download_embedding.py", "w") as f:
            f.write(script)
        
        subprocess.run([sys.executable, "temp_download_embedding.py"], check=True)
        os.remove("temp_download_embedding.py")
        
        print("‚úÖ Embedding model ready!")
        
    except Exception as e:
        print(f"‚ùå Error downloading embedding model: {e}")
        print("Please download manually:")
        print("1. Go to https://huggingface.co/intfloat/multilingual-e5-large")
        print("2. Download all files to models/embedding/")

def download_llm_model():
    """T·∫£i LLM model"""
    print("üì• Downloading LLM model (gpt-oss-20b)...")
    
    model_path = Path("models/llm")
    model_path.mkdir(parents=True, exist_ok=True)
    
    try:
        # T·∫£i model b·∫±ng transformers
        script = """
from transformers import AutoTokenizer, AutoModelForCausalLM
import os

print("Downloading gpt-oss-20b...")
model_name = "gpt-oss-20b"  # Ho·∫∑c ƒë∆∞·ªùng d·∫´n model c·ª• th·ªÉ

try:
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForCausalLM.from_pretrained(model_name)
    
    tokenizer.save_pretrained('models/llm')
    model.save_pretrained('models/llm')
    print("‚úÖ LLM model downloaded successfully!")
except Exception as e:
    print(f"Error: {e}")
    print("Please check model name or download manually")
"""
        
        with open("temp_download_llm.py", "w") as f:
            f.write(script)
        
        subprocess.run([sys.executable, "temp_download_llm.py"], check=True)
        os.remove("temp_download_llm.py")
        
        print("‚úÖ LLM model ready!")
        
    except Exception as e:
        print(f"‚ùå Error downloading LLM model: {e}")
        print("Please download manually:")
        print("1. Go to https://huggingface.co/gpt-oss-20b")
        print("2. Download all files to models/llm/")

def check_models():
    """Ki·ªÉm tra models ƒë√£ t·∫£i"""
    embedding_path = Path("models/embedding")
    llm_path = Path("models/llm")
    
    print("\nüîç Checking downloaded models...")
    
    if embedding_path.exists() and any(embedding_path.iterdir()):
        print("‚úÖ Embedding model found")
        files = list(embedding_path.glob("*"))
        print(f"   Files: {len(files)}")
    else:
        print("‚ùå Embedding model not found")
    
    if llm_path.exists() and any(llm_path.iterdir()):
        print("‚úÖ LLM model found")
        files = list(llm_path.glob("*"))
        print(f"   Files: {len(files)}")
    else:
        print("‚ùå LLM model not found")

def main():
    """Main setup function"""
    print("ü§ñ RAG + LLM Chatbot Model Setup")
    print("=" * 50)
    
    # T·∫°o th∆∞ m·ª•c models
    Path("models").mkdir(exist_ok=True)
    
    # T·∫£i embedding model
    download_embedding_model()
    
    # T·∫£i LLM model
    download_llm_model()
    
    # Ki·ªÉm tra models
    check_models()
    
    print("\n" + "=" * 50)
    print("‚úÖ Model setup completed!")
    print("You can now run: python start.py")

if __name__ == "__main__":
    main()
