"""
Embedding Router
API x·ª≠ l√Ω embedding cho documents
"""

from fastapi import APIRouter, HTTPException, Depends
from fastapi.responses import JSONResponse
from typing import List, Dict, Any, Optional
from pydantic import BaseModel
import os
import json
import logging
from datetime import datetime
from pathlib import Path

# Import services
from services.embedding_service import embedding_service
from db.faiss_store import faiss_store

logger = logging.getLogger(__name__)

router = APIRouter()

# Load documents metadata
METADATA_FILE = "data/documents_metadata.json"

def load_documents_metadata() -> Dict[str, Any]:
    """Load documents metadata"""
    try:
        if os.path.exists(METADATA_FILE):
            with open(METADATA_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {}
    except Exception as e:
        logger.error(f"‚ùå Error loading documents metadata: {e}")
        return {}

class EmbedRequest(BaseModel):
    """Request model cho embed document"""
    chunk_size: int = 500
    chunk_overlap: int = 50

class EmbedResponse(BaseModel):
    """Response model cho embed document"""
    document_id: str
    chunks_created: int
    vectors_stored: int
    processing_time: float
    status: str

class TextEmbedRequest(BaseModel):
    """Request model cho embed text"""
    text: str

class TextEmbedResponse(BaseModel):
    """Response model cho embed text"""
    embedding: List[float]
    dimension: int
    text_length: int

def chunk_text(text: str, chunk_size: int = 500, chunk_overlap: int = 50) -> List[str]:
    """
    Chia text th√†nh c√°c chunks
    
    Args:
        text: VƒÉn b·∫£n c·∫ßn chia
        chunk_size: K√≠ch th∆∞·ªõc m·ªói chunk
        chunk_overlap: Overlap gi·ªØa c√°c chunks
        
    Returns:
        List[str]: Danh s√°ch c√°c chunks
    """
    if not text or not text.strip():
        return []
    
    text = text.strip()
    
    # N·∫øu text ng·∫Øn h∆°n chunk_size, tr·∫£ v·ªÅ to√†n b·ªô
    if len(text) <= chunk_size:
        return [text]
    
    chunks = []
    start = 0
    
    while start < len(text):
        end = start + chunk_size
        
        # N·∫øu kh√¥ng ph·∫£i chunk cu·ªëi, t√¨m v·ªã tr√≠ c·∫Øt ph√π h·ª£p
        if end < len(text):
            # T√¨m d·∫•u c√¢u ho·∫∑c kho·∫£ng tr·∫Øng g·∫ßn nh·∫•t
            for i in range(end, max(start + chunk_size // 2, end - 50), -1):
                if text[i] in '.!?„ÄÇÔºÅÔºü\n':
                    end = i + 1
                    break
                elif text[i] == ' ':
                    end = i
                    break
        
        chunk = text[start:end].strip()
        if chunk:
            chunks.append(chunk)
        
        # Di chuy·ªÉn start v·ªõi overlap
        start = end - chunk_overlap
        if start >= len(text):
            break
    
    return chunks

def read_text_file(file_path: str) -> str:
    """
    ƒê·ªçc n·ªôi dung file text
    
    Args:
        file_path: ƒê∆∞·ªùng d·∫´n file
        
    Returns:
        str: N·ªôi dung file
    """
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    except UnicodeDecodeError:
        # Th·ª≠ v·ªõi encoding kh√°c
        try:
            with open(file_path, 'r', encoding='latin-1') as f:
                return f.read()
        except:
            raise ValueError("Kh√¥ng th·ªÉ ƒë·ªçc file v·ªõi encoding hi·ªán t·∫°i")

@router.post("/embed/document/{document_id}", response_model=EmbedResponse)
async def embed_document(
    document_id: str,
    request: EmbedRequest
) -> EmbedResponse:
    """
    T·∫°o embedding cho document v√† l∆∞u v√†o FAISS
    """
    try:
        start_time = datetime.now()
        
        # Load documents metadata
        documents_metadata = load_documents_metadata()
        
        if document_id not in documents_metadata:
            raise HTTPException(
                status_code=404,
                detail="Kh√¥ng t√¨m th·∫•y t√†i li·ªáu"
            )
        
        doc_metadata = documents_metadata[document_id]
        file_path = doc_metadata["file_path"]
        file_type = doc_metadata["file_type"]
        
        # Ki·ªÉm tra file t·ªìn t·∫°i
        if not os.path.exists(file_path):
            raise HTTPException(
                status_code=404,
                detail="File kh√¥ng t·ªìn t·∫°i"
            )
        
        # ƒê·ªçc n·ªôi dung file
        if file_type == ".txt":
            text_content = read_text_file(file_path)
        elif file_type == ".pdf":
            # TODO: Implement PDF reading
            raise HTTPException(
                status_code=400,
                detail="PDF processing ch∆∞a ƒë∆∞·ª£c implement"
            )
        else:
            raise HTTPException(
                status_code=400,
                detail=f"Kh√¥ng h·ªó tr·ª£ file type: {file_type}"
            )
        
        if not text_content or not text_content.strip():
            raise HTTPException(
                status_code=400,
                detail="File tr·ªëng ho·∫∑c kh√¥ng c√≥ n·ªôi dung"
            )
        
        # Chia text th√†nh chunks
        chunks = chunk_text(
            text_content, 
            chunk_size=request.chunk_size,
            chunk_overlap=request.chunk_overlap
        )
        
        if not chunks:
            raise HTTPException(
                status_code=400,
                detail="Kh√¥ng th·ªÉ chia file th√†nh chunks"
            )
        
        # T·∫°o embeddings cho c√°c chunks
        logger.info(f"üìù Creating embeddings for {len(chunks)} chunks...")
        
        embeddings = embedding_service.generate_embeddings_batch(chunks)
        
        if len(embeddings) != len(chunks):
            raise HTTPException(
                status_code=500,
                detail="S·ªë l∆∞·ª£ng embeddings kh√¥ng kh·ªõp v·ªõi s·ªë chunks"
            )
        
        # Chu·∫©n b·ªã metadata cho FAISS
        vectors_metadata = []
        for i, (chunk, embedding) in enumerate(zip(chunks, embeddings)):
            metadata = {
                "document_id": document_id,
                "chunk_id": f"{document_id}_chunk_{i}",
                "chunk_index": i,
                "content": chunk,
                "content_length": len(chunk),
                "created_at": datetime.now().isoformat(),
                "filename": doc_metadata["filename"]
            }
            vectors_metadata.append(metadata)
        
        # L∆∞u v√†o FAISS
        import numpy as np
        vectors_array = np.array(embeddings, dtype=np.float32)
        vector_ids = faiss_store.add_vectors(vectors_array, vectors_metadata)
        
        processing_time = (datetime.now() - start_time).total_seconds()
        
        logger.info(f"‚úÖ Document {document_id} embedded successfully")
        logger.info(f"üìä Chunks: {len(chunks)}, Vectors: {len(vector_ids)}")
        
        return EmbedResponse(
            document_id=document_id,
            chunks_created=len(chunks),
            vectors_stored=len(vector_ids),
            processing_time=processing_time,
            status="success"
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Error embedding document: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"L·ªói khi t·∫°o embedding: {str(e)}"
        )

@router.post("/embed/text", response_model=TextEmbedResponse)
async def embed_text(request: TextEmbedRequest) -> TextEmbedResponse:
    """
    T·∫°o embedding cho m·ªôt ƒëo·∫°n text
    """
    try:
        if not request.text or not request.text.strip():
            raise HTTPException(
                status_code=400,
                detail="Text kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng"
            )
        
        # T·∫°o embedding
        embedding = embedding_service.generate_embedding(request.text.strip())
        
        return TextEmbedResponse(
            embedding=embedding,
            dimension=len(embedding),
            text_length=len(request.text.strip())
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Error embedding text: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"L·ªói khi t·∫°o embedding: {str(e)}"
        )

@router.get("/embed/stats")
async def get_embedding_stats() -> JSONResponse:
    """
    L·∫•y th·ªëng k√™ v·ªÅ embedding system
    """
    try:
        # Get FAISS stats
        faiss_stats = faiss_store.get_stats()
        
        # Get embedding service info
        embedding_info = embedding_service.get_model_info()
        
        # Get documents metadata
        documents_metadata = load_documents_metadata()
        
        stats = {
            "faiss_store": faiss_stats,
            "embedding_service": embedding_info,
            "documents": {
                "total_documents": len(documents_metadata),
                "processed_documents": len([
                    doc for doc in documents_metadata.values() 
                    if doc.get("processed", False)
                ])
            }
        }
        
        return JSONResponse(
            status_code=200,
            content=stats
        )
        
    except Exception as e:
        logger.error(f"‚ùå Error getting embedding stats: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"L·ªói khi l·∫•y th·ªëng k√™: {str(e)}"
        )

@router.delete("/embed/document/{document_id}")
async def delete_document_embeddings(document_id: str) -> JSONResponse:
    """
    X√≥a t·∫•t c·∫£ embeddings c·ªßa m·ªôt document
    """
    try:
        # Load documents metadata
        documents_metadata = load_documents_metadata()
        
        if document_id not in documents_metadata:
            raise HTTPException(
                status_code=404,
                detail="Kh√¥ng t√¨m th·∫•y t√†i li·ªáu"
            )
        
        # X√≥a vectors t·ª´ FAISS
        deleted_count = faiss_store.delete_document_vectors(document_id)
        
        logger.info(f"‚úÖ Deleted {deleted_count} vectors for document {document_id}")
        
        return JSONResponse(
            status_code=200,
            content={
                "message": "Embeddings ƒë√£ ƒë∆∞·ª£c x√≥a th√†nh c√¥ng",
                "document_id": document_id,
                "vectors_deleted": deleted_count
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Error deleting document embeddings: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"L·ªói khi x√≥a embeddings: {str(e)}"
        )

@router.get("/embed/document/{document_id}/vectors")
async def get_document_vectors(document_id: str) -> JSONResponse:
    """
    L·∫•y th√¥ng tin v·ªÅ vectors c·ªßa m·ªôt document
    """
    try:
        # Load documents metadata
        documents_metadata = load_documents_metadata()
        
        if document_id not in documents_metadata:
            raise HTTPException(
                status_code=404,
                detail="Kh√¥ng t√¨m th·∫•y t√†i li·ªáu"
            )
        
        # L·∫•y vectors t·ª´ FAISS
        vectors = faiss_store.get_document_vectors(document_id)
        
        # Ch·ªâ tr·∫£ v·ªÅ metadata, kh√¥ng tr·∫£ v·ªÅ vector data
        vectors_info = []
        for vector in vectors:
            vector_info = {
                "vector_id": vector.get("vector_id"),
                "chunk_id": vector.get("chunk_id"),
                "chunk_index": vector.get("chunk_index"),
                "content_preview": vector.get("content", "")[:200] + "...",
                "content_length": vector.get("content_length"),
                "created_at": vector.get("created_at")
            }
            vectors_info.append(vector_info)
        
        return JSONResponse(
            status_code=200,
            content={
                "document_id": document_id,
                "vectors_count": len(vectors_info),
                "vectors": vectors_info
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Error getting document vectors: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"L·ªói khi l·∫•y th√¥ng tin vectors: {str(e)}"
        )
