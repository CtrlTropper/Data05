"""
Documents management router
Router qu·∫£n l√Ω t√†i li·ªáu (upload, x√≥a, ch·ªçn t√†i li·ªáu)
"""

from fastapi import APIRouter, UploadFile, File, HTTPException, Depends, Form
from fastapi.responses import JSONResponse
from typing import List, Optional, Dict, Any
from pydantic import BaseModel
import uuid
import os
import json
import shutil
from datetime import datetime
from pathlib import Path
import logging

logger = logging.getLogger(__name__)

router = APIRouter()

# Global metadata storage
DOCUMENTS_METADATA = {}
METADATA_FILE = "data/documents_metadata.json"

# Ensure data directory exists
Path("data/docs").mkdir(parents=True, exist_ok=True)
Path("data").mkdir(parents=True, exist_ok=True)

def load_metadata():
    """Load metadata t·ª´ file JSON"""
    global DOCUMENTS_METADATA
    try:
        if os.path.exists(METADATA_FILE):
            with open(METADATA_FILE, 'r', encoding='utf-8') as f:
                DOCUMENTS_METADATA = json.load(f)
            logger.info(f"‚úÖ Loaded {len(DOCUMENTS_METADATA)} documents metadata")
        else:
            DOCUMENTS_METADATA = {}
            logger.info("üÜï Created new metadata storage")
    except Exception as e:
        logger.error(f"‚ùå Error loading metadata: {e}")
        DOCUMENTS_METADATA = {}

def save_metadata():
    """Save metadata v√†o file JSON"""
    try:
        with open(METADATA_FILE, 'w', encoding='utf-8') as f:
            json.dump(DOCUMENTS_METADATA, f, ensure_ascii=False, indent=2)
        logger.info("üíæ Metadata saved successfully")
    except Exception as e:
        logger.error(f"‚ùå Error saving metadata: {e}")

def validate_file_type(filename: str) -> bool:
    """Validate file type (ch·ªâ cho ph√©p PDF v√† TXT)"""
    allowed_extensions = ['.pdf', '.txt']
    file_ext = Path(filename).suffix.lower()
    return file_ext in allowed_extensions

def get_file_size(file_path: str) -> int:
    """L·∫•y k√≠ch th∆∞·ªõc file"""
    try:
        return os.path.getsize(file_path)
    except:
        return 0

class DocumentResponse(BaseModel):
    """Response model cho document"""
    id: str
    filename: str
    size: int
    upload_time: str
    file_path: str
    file_type: str
    selected: bool = False

class DocumentListResponse(BaseModel):
    """Response model cho danh s√°ch documents"""
    documents: List[DocumentResponse]
    total: int

class SelectDocumentRequest(BaseModel):
    """Request model cho ch·ªçn t√†i li·ªáu"""
    selected: bool = True

# Import PDF processor
from services.pdf_processor import pdf_processor

# Load metadata khi kh·ªüi ƒë·ªông
load_metadata()

async def process_document_content(file_path: str, filename: str, force_ocr: bool = False) -> Dict[str, Any]:
    """
    X·ª≠ l√Ω n·ªôi dung t√†i li·ªáu (PDF v·ªõi OCR support)
    
    Args:
        file_path: ƒê∆∞·ªùng d·∫´n file
        filename: T√™n file
        force_ocr: B·∫Øt bu·ªôc s·ª≠ d·ª•ng OCR
        
    Returns:
        Dict[str, Any]: Processing information
    """
    try:
        file_ext = filename.lower().split('.')[-1]
        
        if file_ext == 'pdf':
            return await process_pdf_with_ocr(file_path, force_ocr)
        elif file_ext in ['txt', 'md']:
            return await process_text_file(file_path)
        else:
            return {
                'processing_type': 'unsupported',
                'message': f'File type .{file_ext} is not supported yet'
            }
            
    except Exception as e:
        logger.error(f"‚ùå Error processing document content: {e}")
        return {
            'processing_type': 'error',
            'error': str(e)
        }

async def process_pdf_with_ocr(file_path: str, force_ocr: bool = False) -> Dict[str, Any]:
    """
    X·ª≠ l√Ω file PDF v·ªõi OCR support
    
    Args:
        file_path: ƒê∆∞·ªùng d·∫´n file PDF
        force_ocr: B·∫Øt bu·ªôc s·ª≠ d·ª•ng OCR
        
    Returns:
        Dict[str, Any]: PDF processing information
    """
    try:
        if not pdf_processor.is_initialized:
            logger.warning("‚ö†Ô∏è PDF processor not initialized, attempting to initialize...")
            await pdf_processor.initialize()
        
        # Process PDF
        extracted_text, metadata = pdf_processor.process_pdf(file_path, force_ocr)
        
        # Save extracted text to file
        text_file_path = file_path.replace('.pdf', '_extracted.txt')
        with open(text_file_path, 'w', encoding='utf-8') as f:
            f.write(extracted_text)
        
        # Update metadata with text file path
        metadata['extracted_text_file'] = text_file_path
        metadata['text_length'] = len(extracted_text)
        
        logger.info(f"‚úÖ PDF processed: {metadata['processing_type']}, {metadata['total_pages']} pages")
        return metadata
        
    except Exception as e:
        logger.error(f"‚ùå Error processing PDF: {e}")
        return {
            'processing_type': 'error',
            'error': str(e)
        }

async def process_text_file(file_path: str) -> Dict[str, Any]:
    """
    X·ª≠ l√Ω file text
    
    Args:
        file_path: ƒê∆∞·ªùng d·∫´n file text
        
    Returns:
        Dict[str, Any]: Text processing information
    """
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        return {
            'processing_type': 'text-based',
            'text_length': len(content),
            'total_pages': 1,
            'ocr_language': None
        }
        
    except Exception as e:
        logger.error(f"‚ùå Error processing text file: {e}")
        return {
            'processing_type': 'error',
            'error': str(e)
        }

@router.post("/documents/upload")
async def upload_document(
    file: UploadFile = File(...),
    force_ocr: bool = Form(False)
) -> JSONResponse:
    """
    Upload t√†i li·ªáu m·ªõi (PDF/TXT)
    """
    try:
        # Validate file type
        if not validate_file_type(file.filename):
            raise HTTPException(
                status_code=400, 
                detail="Ch·ªâ h·ªó tr·ª£ file PDF v√† TXT"
            )
        
        # Validate file size (50MB max)
        max_size = 50 * 1024 * 1024  # 50MB
        if file.size and file.size > max_size:
            raise HTTPException(
                status_code=400,
                detail="File qu√° l·ªõn. K√≠ch th∆∞·ªõc t·ªëi ƒëa l√† 50MB"
            )
        
        # Generate document ID
        document_id = str(uuid.uuid4())
        
        # Create safe filename
        safe_filename = f"{document_id}_{file.filename}"
        file_path = os.path.join("data/docs", safe_filename)
        
        # Save file
        with open(file_path, "wb") as buffer:
            shutil.copyfileobj(file.file, buffer)
        
        # Get actual file size
        actual_size = get_file_size(file_path)
        
        # Process document content (PDF with OCR support)
        processing_info = await process_document_content(file_path, file.filename, force_ocr)
        
        # Add to vector store with Uploads category
        from services.data_initialization import data_initialization_service
        vector_result = await data_initialization_service.add_uploaded_document(file_path, file.filename)
        if vector_result.get("success"):
            processing_info["vector_store"] = {
                "added": True,
                "chunks_created": vector_result.get("chunks_created", 0),
                "category": "Uploads"
            }
        else:
            processing_info["vector_store"] = {
                "added": False,
                "error": vector_result.get("error", "Unknown error")
            }
        
        # Create metadata
        document_metadata = {
            "id": document_id,
            "filename": file.filename,
            "file_path": file_path,
            "size": actual_size,
            "upload_time": datetime.now().isoformat(),
            "file_type": Path(file.filename).suffix.lower(),
            "selected": False,
            "processing_info": processing_info
        }
        
        # Save to metadata
        DOCUMENTS_METADATA[document_id] = document_metadata
        save_metadata()
        
        logger.info(f"‚úÖ Document uploaded: {document_id} - {file.filename}")
        
        return JSONResponse(
            status_code=201,
            content={
                "message": "T√†i li·ªáu ƒë√£ ƒë∆∞·ª£c upload th√†nh c√¥ng",
                "document_id": document_id,
                "filename": file.filename,
                "size": actual_size,
                "file_type": document_metadata["file_type"],
                "processing_info": processing_info
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Error uploading document: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"L·ªói khi upload t√†i li·ªáu: {str(e)}"
        )

@router.get("/documents", response_model=DocumentListResponse)
async def get_documents(
    skip: int = 0,
    limit: int = 100
) -> DocumentListResponse:
    """
    L·∫•y danh s√°ch t√†i li·ªáu
    """
    try:
        # Load latest metadata
        load_metadata()
        
        # Convert to list and sort by upload time (newest first)
        documents_list = list(DOCUMENTS_METADATA.values())
        documents_list.sort(key=lambda x: x["upload_time"], reverse=True)
        
        # Apply pagination
        total = len(documents_list)
        paginated_docs = documents_list[skip:skip + limit]
        
        # Convert to response format
        response_docs = [
            DocumentResponse(
                id=doc["id"],
                filename=doc["filename"],
                size=doc["size"],
                upload_time=doc["upload_time"],
                file_path=doc["file_path"],
                file_type=doc["file_type"],
                selected=doc.get("selected", False)
            )
            for doc in paginated_docs
        ]
        
        return DocumentListResponse(
            documents=response_docs,
            total=total
        )
        
    except Exception as e:
        logger.error(f"‚ùå Error getting documents: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"L·ªói khi l·∫•y danh s√°ch t√†i li·ªáu: {str(e)}"
        )

@router.get("/documents/{document_id}", response_model=DocumentResponse)
async def get_document(document_id: str) -> DocumentResponse:
    """
    L·∫•y th√¥ng tin chi ti·∫øt m·ªôt t√†i li·ªáu
    """
    try:
        # Load latest metadata
        load_metadata()
        
        if document_id not in DOCUMENTS_METADATA:
            raise HTTPException(
                status_code=404, 
                detail="Kh√¥ng t√¨m th·∫•y t√†i li·ªáu"
            )
        
        doc = DOCUMENTS_METADATA[document_id]
        
        return DocumentResponse(
            id=doc["id"],
            filename=doc["filename"],
            size=doc["size"],
            upload_time=doc["upload_time"],
            file_path=doc["file_path"],
            file_type=doc["file_type"],
            selected=doc.get("selected", False)
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Error getting document: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"L·ªói khi l·∫•y th√¥ng tin t√†i li·ªáu: {str(e)}"
        )

@router.delete("/documents/{document_id}")
async def delete_document(document_id: str) -> JSONResponse:
    """
    X√≥a t√†i li·ªáu
    """
    try:
        # Load latest metadata
        load_metadata()
        
        if document_id not in DOCUMENTS_METADATA:
            raise HTTPException(
                status_code=404,
                detail="Kh√¥ng t√¨m th·∫•y t√†i li·ªáu"
            )
        
        doc = DOCUMENTS_METADATA[document_id]
        file_path = doc["file_path"]
        
        # Delete file if exists
        if os.path.exists(file_path):
            os.remove(file_path)
            logger.info(f"üóëÔ∏è Deleted file: {file_path}")
        
        # Remove from metadata
        del DOCUMENTS_METADATA[document_id]
        save_metadata()
        
        logger.info(f"‚úÖ Document deleted: {document_id}")
        
        return JSONResponse(
            status_code=200,
            content={
                "message": "T√†i li·ªáu ƒë√£ ƒë∆∞·ª£c x√≥a th√†nh c√¥ng",
                "document_id": document_id
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Error deleting document: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"L·ªói khi x√≥a t√†i li·ªáu: {str(e)}"
        )

@router.post("/documents/{document_id}/select")
async def select_document(
    document_id: str,
    request: SelectDocumentRequest
) -> JSONResponse:
    """
    Ch·ªçn/b·ªè ch·ªçn t√†i li·ªáu ƒë·ªÉ h·ªèi
    """
    try:
        # Load latest metadata
        load_metadata()
        
        if document_id not in DOCUMENTS_METADATA:
            raise HTTPException(
                status_code=404,
                detail="Kh√¥ng t√¨m th·∫•y t√†i li·ªáu"
            )
        
        # Update selection status
        DOCUMENTS_METADATA[document_id]["selected"] = request.selected
        save_metadata()
        
        action = "ch·ªçn" if request.selected else "b·ªè ch·ªçn"
        logger.info(f"‚úÖ Document {action}: {document_id}")
        
        return JSONResponse(
            status_code=200,
            content={
                "message": f"T√†i li·ªáu ƒë√£ ƒë∆∞·ª£c {action} th√†nh c√¥ng",
                "document_id": document_id,
                "selected": request.selected
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Error selecting document: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"L·ªói khi ch·ªçn t√†i li·ªáu: {str(e)}"
        )

@router.get("/documents/selected")
async def get_selected_documents() -> JSONResponse:
    """
    L·∫•y danh s√°ch t√†i li·ªáu ƒë√£ ƒë∆∞·ª£c ch·ªçn
    """
    try:
        # Load latest metadata
        load_metadata()
        
        selected_docs = [
            {
                "id": doc["id"],
                "filename": doc["filename"],
                "size": doc["size"],
                "upload_time": doc["upload_time"],
                "file_type": doc["file_type"]
            }
            for doc in DOCUMENTS_METADATA.values()
            if doc.get("selected", False)
        ]
        
        return JSONResponse(
            status_code=200,
            content={
                "selected_documents": selected_docs,
                "count": len(selected_docs)
            }
        )
        
    except Exception as e:
        logger.error(f"‚ùå Error getting selected documents: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"L·ªói khi l·∫•y t√†i li·ªáu ƒë√£ ch·ªçn: {str(e)}"
        )

@router.get("/documents/{document_id}/content")
async def get_document_content(document_id: str) -> JSONResponse:
    """
    L·∫•y n·ªôi dung t√†i li·ªáu (ch·ªâ cho file TXT)
    """
    try:
        # Load latest metadata
        load_metadata()
        
        if document_id not in DOCUMENTS_METADATA:
            raise HTTPException(
                status_code=404,
                detail="Kh√¥ng t√¨m th·∫•y t√†i li·ªáu"
            )
        
        doc = DOCUMENTS_METADATA[document_id]
        
        # Ch·ªâ h·ªó tr·ª£ file TXT
        if doc["file_type"] != ".txt":
            raise HTTPException(
                status_code=400,
                detail="Ch·ªâ h·ªó tr·ª£ xem n·ªôi dung file TXT"
            )
        
        # Read file content
        file_path = doc["file_path"]
        if not os.path.exists(file_path):
            raise HTTPException(
                status_code=404,
                detail="File kh√¥ng t·ªìn t·∫°i"
            )
        
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        return JSONResponse(
            status_code=200,
            content={
                "document_id": document_id,
                "filename": doc["filename"],
                "content": content,
                "content_length": len(content)
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Error getting document content: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"L·ªói khi ƒë·ªçc n·ªôi dung t√†i li·ªáu: {str(e)}"
        )
