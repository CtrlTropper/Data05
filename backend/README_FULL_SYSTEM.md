# RAG + LLM Chatbot System - HÆ°á»›ng dáº«n hoÃ n chá»‰nh

Há»‡ thá»‘ng chatbot RAG + LLM hoáº¡t Ä‘á»™ng hoÃ n toÃ n offline vá»›i FastAPI backend.

## ğŸ¯ **Tá»”NG QUAN Há»† THá»NG**

### **Kiáº¿n trÃºc**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚    â”‚    Backend      â”‚    â”‚   AI Models     â”‚
â”‚   (ReactJS)     â”‚â—„â”€â”€â–ºâ”‚   (FastAPI)     â”‚â—„â”€â”€â–ºâ”‚   (Offline)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Vector DB      â”‚
                    â”‚  (FAISS)        â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **CÃ¡c Module chÃ­nh**
- âœ… **Documents**: Upload, quáº£n lÃ½ tÃ i liá»‡u
- âœ… **Embedding**: Táº¡o embeddings tá»« tÃ i liá»‡u
- âœ… **Search**: TÃ¬m kiáº¿m vector vá»›i FAISS
- âœ… **Chat**: Chatbot RAG + LLM
- âœ… **Health**: Kiá»ƒm tra tráº¡ng thÃ¡i há»‡ thá»‘ng

## ğŸš€ **CÃ€I Äáº¶T VÃ€ KHá»I CHáº Y**

### **1. CÃ i Ä‘áº·t Dependencies**
```bash
cd backend
pip install -r requirements.txt
```

### **2. Táº£i Models (Láº§n Ä‘áº§u)**
```bash
# Táº£i cÃ¡c AI models
python setup_models.py
```

### **3. Khá»Ÿi cháº¡y há»‡ thá»‘ng**
```bash
# CÃ¡ch 1: Sá»­ dá»¥ng script khá»Ÿi cháº¡y
python start.py

# CÃ¡ch 2: Cháº¡y trá»±c tiáº¿p
uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```

### **4. Kiá»ƒm tra há»‡ thá»‘ng**
```bash
# Test toÃ n bá»™ há»‡ thá»‘ng
python test_full_system.py
```

## ğŸ“š **API ENDPOINTS**

### **Health Check**
- `GET /api/health` - Kiá»ƒm tra tráº¡ng thÃ¡i há»‡ thá»‘ng

### **Document Management**
- `POST /api/documents/upload` - Upload tÃ i liá»‡u
- `GET /api/documents` - Láº¥y danh sÃ¡ch tÃ i liá»‡u
- `GET /api/documents/{id}` - Láº¥y thÃ´ng tin tÃ i liá»‡u
- `DELETE /api/documents/{id}` - XÃ³a tÃ i liá»‡u
- `POST /api/documents/{id}/select` - Chá»n tÃ i liá»‡u

### **Embedding System**
- `POST /api/embed/document/{id}` - Táº¡o embeddings cho tÃ i liá»‡u
- `POST /api/embed/text` - Táº¡o embedding cho text
- `GET /api/embed/stats` - Thá»‘ng kÃª embedding

### **Search System**
- `POST /api/search/text` - TÃ¬m kiáº¿m báº±ng text
- `POST /api/search/vector` - TÃ¬m kiáº¿m báº±ng vector
- `GET /api/search/document/{id}` - Láº¥y contexts cá»§a document
- `GET /api/search/stats` - Thá»‘ng kÃª search

### **Chat System**
- `POST /api/chat` - Chat cÆ¡ báº£n
- `POST /api/chat/document/{id}` - Chat vá»›i document
- `POST /api/chat/stream` - Streaming chat
- `GET /api/chat/stats` - Thá»‘ng kÃª chat

## ğŸ”§ **Cáº¤U TRÃšC Dá»° ÃN**

```
backend/
â”œâ”€â”€ main.py                 # FastAPI app chÃ­nh
â”œâ”€â”€ start.py               # Script khá»Ÿi cháº¡y
â”œâ”€â”€ setup_models.py        # Script táº£i models
â”œâ”€â”€ test_full_system.py    # Test toÃ n bá»™ há»‡ thá»‘ng
â”œâ”€â”€ requirements.txt       # Dependencies
â”œâ”€â”€ env.example           # Environment variables
â”œâ”€â”€ routers/              # API routes
â”‚   â”œâ”€â”€ health.py         # Health check
â”‚   â”œâ”€â”€ documents.py      # Document management
â”‚   â”œâ”€â”€ embedding.py      # Embedding system
â”‚   â”œâ”€â”€ search.py         # Search system
â”‚   â””â”€â”€ chat.py          # Chat system
â”œâ”€â”€ services/             # Business logic
â”‚   â”œâ”€â”€ config.py         # Configuration
â”‚   â”œâ”€â”€ embedding_service.py # Embedding service
â”‚   â”œâ”€â”€ llm_service.py    # LLM service
â”‚   â”œâ”€â”€ model_manager.py  # Model manager
â”‚   â”œâ”€â”€ document_service.py # Document service
â”‚   â””â”€â”€ rag_service.py    # RAG service
â”œâ”€â”€ models/               # Data models
â”‚   â”œâ”€â”€ schemas.py        # Pydantic schemas
â”‚   â””â”€â”€ database.py       # SQLAlchemy models
â”œâ”€â”€ db/                   # Database layer
â”‚   â”œâ”€â”€ database.py       # Database connection
â”‚   â”œâ”€â”€ faiss_store.py    # FAISS vector store
â”‚   â””â”€â”€ vector_db.py      # Vector database
â”œâ”€â”€ data/                 # Data storage
â”‚   â”œâ”€â”€ docs/            # Documents
â”‚   â”œâ”€â”€ faiss_store/     # FAISS index
â”‚   â”œâ”€â”€ metadata/        # Metadata
â”‚   â””â”€â”€ documents_metadata.json
â”œâ”€â”€ models/               # AI Models
â”‚   â”œâ”€â”€ embedding/       # Embedding model
â”‚   â””â”€â”€ llm/            # LLM model
â””â”€â”€ uploads/             # Upload directory
```

## ğŸ§ª **TESTING**

### **1. Test tá»«ng module**
```bash
# Test search
python test_search.py

# Test chat
python test_chat.py
```

### **2. Test toÃ n bá»™ há»‡ thá»‘ng**
```bash
# Test tÃ­ch há»£p
python test_full_system.py
```

### **3. Manual testing**
```bash
# Health check
curl http://localhost:8000/api/health

# Upload document
curl -X POST "http://localhost:8000/api/documents/upload" \
  -F "file=@document.txt"

# Chat
curl -X POST "http://localhost:8000/api/chat" \
  -H "Content-Type: application/json" \
  -d '{"question": "TrÃ­ tuá»‡ nhÃ¢n táº¡o lÃ  gÃ¬?"}'
```

## ğŸ“Š **WORKFLOW Sá»¬ Dá»¤NG**

### **1. Upload vÃ  xá»­ lÃ½ tÃ i liá»‡u**
```bash
# 1. Upload document
curl -X POST "http://localhost:8000/api/documents/upload" \
  -F "file=@document.txt"

# 2. Táº¡o embeddings
curl -X POST "http://localhost:8000/api/embed/document/{doc_id}" \
  -H "Content-Type: application/json" \
  -d '{"chunk_size": 500, "chunk_overlap": 50}'
```

### **2. Chat vá»›i tÃ i liá»‡u**
```bash
# Chat vá»›i toÃ n bá»™ documents
curl -X POST "http://localhost:8000/api/chat" \
  -H "Content-Type: application/json" \
  -d '{"question": "Ná»™i dung chÃ­nh lÃ  gÃ¬?", "top_k": 5}'

# Chat vá»›i document cá»¥ thá»ƒ
curl -X POST "http://localhost:8000/api/chat/document/{doc_id}" \
  -H "Content-Type: application/json" \
  -d '{"question": "TÃ³m táº¯t tÃ i liá»‡u nÃ y"}'
```

### **3. TÃ¬m kiáº¿m**
```bash
# TÃ¬m kiáº¿m text
curl -X POST "http://localhost:8000/api/search/text" \
  -H "Content-Type: application/json" \
  -d '{"query": "machine learning", "top_k": 5}'
```

## âš¡ **PERFORMANCE**

### **Benchmarks**
- **Document Upload**: ~1-5s (tÃ¹y kÃ­ch thÆ°á»›c)
- **Embedding Creation**: ~10-30s (tÃ¹y sá»‘ chunks)
- **Search**: ~100-500ms
- **Chat**: ~2-8s (bao gá»“m LLM generation)
- **Streaming Chat**: ~1-3s (first token)

### **Memory Requirements**
- **RAM**: Tá»‘i thiá»ƒu 16GB
- **VRAM**: Khuyáº¿n nghá»‹ 12GB+ (náº¿u dÃ¹ng GPU)
- **Storage**: ~50GB cho models

## ğŸ” **TROUBLESHOOTING**

### **1. Models khÃ´ng load Ä‘Æ°á»£c**
```bash
# Kiá»ƒm tra thÆ° má»¥c models
ls -la models/embedding/
ls -la models/llm/

# Táº£i láº¡i models
python setup_models.py
```

### **2. Dependencies lá»—i**
```bash
# CÃ i Ä‘áº·t láº¡i dependencies
pip install -r requirements.txt

# Hoáº·c sá»­ dá»¥ng script khá»Ÿi cháº¡y
python start.py
```

### **3. Server khÃ´ng start**
```bash
# Kiá»ƒm tra port 8000
netstat -an | grep 8000

# Cháº¡y vá»›i port khÃ¡c
uvicorn main:app --port 8001 --reload
```

### **4. Memory issues**
```bash
# Kiá»ƒm tra RAM usage
htop

# Restart server
python start.py
```

## ğŸ“ **CONFIGURATION**

### **Environment Variables**
```bash
# Copy vÃ  chá»‰nh sá»­a
cp env.example .env

# CÃ¡c biáº¿n quan trá»ng
EMBEDDING_MODEL_PATH=models/embedding
LLM_MODEL_PATH=models/llm
FAISS_INDEX_PATH=data/faiss_store
MAX_FILE_SIZE=52428800
DEFAULT_CHUNK_SIZE=500
DEFAULT_TOP_K=5
```

### **Model Configuration**
```python
# Trong services/config.py
EMBEDDING_MODEL_PATH = "models/embedding"
LLM_MODEL_PATH = "models/llm"
DEFAULT_CHUNK_SIZE = 500
DEFAULT_TOP_K = 5
MAX_TOKENS = 1000
TEMPERATURE = 0.7
```

## ğŸ¯ **TÃNH NÄ‚NG Ná»”I Báº¬T**

### **Offline Operation**
- âœ… HoÃ n toÃ n offline, khÃ´ng cáº§n internet
- âœ… Models load tá»« local storage
- âœ… KhÃ´ng gá»i external APIs

### **RAG System**
- âœ… Retrieval-Augmented Generation
- âœ… Vector search vá»›i FAISS
- âœ… Context-aware responses
- âœ… Source tracking

### **Multi-document Support**
- âœ… Upload multiple documents
- âœ… Document-specific chat
- âœ… Global search across documents
- âœ… Document selection

### **Performance**
- âœ… Fast vector search
- âœ… Streaming responses
- âœ… Batch processing
- âœ… Memory optimization

## ğŸš€ **DEPLOYMENT**

### **Development**
```bash
python start.py
```

### **Production**
```bash
# Sá»­ dá»¥ng gunicorn
pip install gunicorn
gunicorn main:app -w 4 -k uvicorn.workers.UvicornWorker --bind 0.0.0.0:8000
```

### **Docker**
```bash
# Build image
docker build -t rag-chatbot .

# Run container
docker run -p 8000:8000 rag-chatbot
```

## ğŸ“ **SUPPORT**

### **Logs**
```bash
# Xem logs
tail -f logs/app.log

# Debug mode
DEBUG=true python start.py
```

### **API Documentation**
- Swagger UI: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc

### **Health Check**
```bash
curl http://localhost:8000/api/health
```

---

**ğŸ‰ Há»‡ thá»‘ng RAG + LLM Chatbot Ä‘Ã£ sáºµn sÃ ng sá»­ dá»¥ng!**
