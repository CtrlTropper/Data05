"""
Test script cho deployment
Kiá»ƒm tra toÃ n bá»™ há»‡ thá»‘ng sau khi triá»ƒn khai
"""

import asyncio
import httpx
import time
import os
import sys
from pathlib import Path

# Add backend to path
sys.path.append(os.path.join(os.path.dirname(__file__), 'backend'))

async def test_backend_health():
    """Test backend health check"""
    print("ğŸ” Testing backend health...")
    try:
        async with httpx.AsyncClient() as client:
            response = await client.get("http://localhost:8000/api/health")
            if response.status_code == 200:
                print("âœ… Backend health check passed")
                return True
            else:
                print(f"âŒ Backend health check failed: {response.status_code}")
                return False
    except Exception as e:
        print(f"âŒ Backend health check error: {e}")
        return False

async def test_frontend_health():
    """Test frontend health check"""
    print("ğŸ” Testing frontend health...")
    try:
        async with httpx.AsyncClient() as client:
            response = await client.get("http://localhost:80/health")
            if response.status_code == 200:
                print("âœ… Frontend health check passed")
                return True
            else:
                print(f"âŒ Frontend health check failed: {response.status_code}")
                return False
    except Exception as e:
        print(f"âŒ Frontend health check error: {e}")
        return False

async def test_document_upload():
    """Test document upload"""
    print("ğŸ” Testing document upload...")
    try:
        # Create test document
        test_content = """
        TrÃ­ tuá»‡ nhÃ¢n táº¡o (AI) lÃ  má»™t lÄ©nh vá»±c khoa há»c mÃ¡y tÃ­nh táº­p trung vÃ o viá»‡c táº¡o ra cÃ¡c há»‡ thá»‘ng cÃ³ kháº£ nÄƒng thá»±c hiá»‡n cÃ¡c tÃ¡c vá»¥ thÃ´ng minh.
        Machine learning lÃ  má»™t nhÃ¡nh con cá»§a AI, cho phÃ©p mÃ¡y tÃ­nh há»c há»i tá»« dá»¯ liá»‡u mÃ  khÃ´ng cáº§n láº­p trÃ¬nh rÃµ rÃ ng.
        Deep learning lÃ  má»™t táº­p há»£p con cá»§a machine learning, sá»­ dá»¥ng máº¡ng nÆ¡-ron nhÃ¢n táº¡o vá»›i nhiá»u lá»›p Ä‘á»ƒ phÃ¢n tÃ­ch dá»¯ liá»‡u.
        """
        
        with open("test_document.txt", "w", encoding="utf-8") as f:
            f.write(test_content)
        
        async with httpx.AsyncClient() as client:
            with open("test_document.txt", "rb") as f:
                files = {"file": ("test_document.txt", f, "text/plain")}
                response = await client.post("http://localhost:8000/api/documents/upload", files=files)
            
            if response.status_code == 201:
                data = response.json()
                doc_id = data.get("document_id")
                print(f"âœ… Document upload successful. ID: {doc_id}")
                return doc_id
            else:
                print(f"âŒ Document upload failed: {response.status_code}")
                return None
    except Exception as e:
        print(f"âŒ Document upload error: {e}")
        return None

async def test_embedding_generation(doc_id):
    """Test embedding generation"""
    print("ğŸ” Testing embedding generation...")
    try:
        async with httpx.AsyncClient(timeout=60.0) as client:
            response = await client.post(
                f"http://localhost:8000/api/embed/document/{doc_id}",
                json={"chunk_size": 500, "chunk_overlap": 50}
            )
            
            if response.status_code == 200:
                data = response.json()
                chunks = data.get("chunks_processed", 0)
                print(f"âœ… Embedding generation successful. Chunks: {chunks}")
                return True
            else:
                print(f"âŒ Embedding generation failed: {response.status_code}")
                return False
    except Exception as e:
        print(f"âŒ Embedding generation error: {e}")
        return False

async def test_chat_functionality():
    """Test chat functionality"""
    print("ğŸ” Testing chat functionality...")
    try:
        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.post(
                "http://localhost:8000/api/chat",
                json={
                    "question": "TrÃ­ tuá»‡ nhÃ¢n táº¡o lÃ  gÃ¬?",
                    "top_k": 5
                }
            )
            
            if response.status_code == 200:
                data = response.json()
                answer = data.get("response", "")
                sources = data.get("sources", [])
                print(f"âœ… Chat functionality successful")
                print(f"   Answer length: {len(answer)} characters")
                print(f"   Sources: {len(sources)} chunks")
                return True
            else:
                print(f"âŒ Chat functionality failed: {response.status_code}")
                return False
    except Exception as e:
        print(f"âŒ Chat functionality error: {e}")
        return False

async def test_streaming_chat():
    """Test streaming chat"""
    print("ğŸ” Testing streaming chat...")
    try:
        async with httpx.AsyncClient(timeout=None) as client:
            response = await client.post(
                "http://localhost:8000/api/chat/stream",
                json={
                    "question": "HÃ£y giáº£i thÃ­ch vá» machine learning",
                    "top_k": 3
                },
                headers={"Accept": "text/event-stream"}
            )
            
            if response.status_code == 200:
                print("âœ… Streaming chat started")
                chunk_count = 0
                async for chunk in response.aiter_bytes():
                    chunk_count += 1
                    if chunk_count > 10:  # Limit for testing
                        break
                
                print(f"âœ… Streaming chat successful. Received {chunk_count} chunks")
                return True
            else:
                print(f"âŒ Streaming chat failed: {response.status_code}")
                return False
    except Exception as e:
        print(f"âŒ Streaming chat error: {e}")
        return False

async def test_system_stats():
    """Test system statistics"""
    print("ğŸ” Testing system statistics...")
    try:
        async with httpx.AsyncClient() as client:
            response = await client.get("http://localhost:8000/api/chat/stats")
            
            if response.status_code == 200:
                data = response.json()
                print("âœ… System statistics retrieved:")
                print(f"   LLM Service: {data.get('llm_service', {}).get('loaded', False)}")
                print(f"   Embedding Service: {data.get('embedding_service', {}).get('loaded', False)}")
                print(f"   FAISS Store: {data.get('faiss_store', {}).get('total_vectors', 0)} vectors")
                return True
            else:
                print(f"âŒ System statistics failed: {response.status_code}")
                return False
    except Exception as e:
        print(f"âŒ System statistics error: {e}")
        return False

async def test_offline_operation():
    """Test offline operation"""
    print("ğŸ” Testing offline operation...")
    try:
        # Test that models are loaded from local files
        async with httpx.AsyncClient() as client:
            response = await client.get("http://localhost:8000/api/chat/stats")
            
            if response.status_code == 200:
                data = response.json()
                llm_loaded = data.get('llm_service', {}).get('loaded', False)
                embedding_loaded = data.get('embedding_service', {}).get('loaded', False)
                
                if llm_loaded and embedding_loaded:
                    print("âœ… Offline operation successful - models loaded from local files")
                    return True
                else:
                    print("âŒ Offline operation failed - models not loaded")
                    return False
            else:
                print(f"âŒ Offline operation test failed: {response.status_code}")
                return False
    except Exception as e:
        print(f"âŒ Offline operation error: {e}")
        return False

async def test_performance():
    """Test system performance"""
    print("ğŸ” Testing system performance...")
    try:
        questions = [
            "TrÃ­ tuá»‡ nhÃ¢n táº¡o lÃ  gÃ¬?",
            "Machine learning hoáº¡t Ä‘á»™ng nhÆ° tháº¿ nÃ o?",
            "Deep learning cÃ³ nhá»¯ng á»©ng dá»¥ng gÃ¬?",
            "Neural networks lÃ  gÃ¬?",
            "AI cÃ³ nhá»¯ng lá»£i Ã­ch gÃ¬?"
        ]
        
        total_time = 0
        successful_requests = 0
        
        async with httpx.AsyncClient(timeout=30.0) as client:
            for i, question in enumerate(questions, 1):
                start_time = time.time()
                try:
                    response = await client.post(
                        "http://localhost:8000/api/chat",
                        json={"question": question, "top_k": 3}
                    )
                    end_time = time.time()
                    
                    if response.status_code == 200:
                        request_time = end_time - start_time
                        total_time += request_time
                        successful_requests += 1
                        print(f"   Question {i}: {request_time:.2f}s")
                    else:
                        print(f"   Question {i}: Failed - {response.status_code}")
                except Exception as e:
                    print(f"   Question {i}: Error - {e}")
        
        if successful_requests > 0:
            avg_time = total_time / successful_requests
            print(f"âœ… Performance test completed:")
            print(f"   Successful: {successful_requests}/{len(questions)}")
            print(f"   Average time: {avg_time:.2f}s per question")
            print(f"   Total time: {total_time:.2f}s")
            return True
        else:
            print("âŒ Performance test failed - no successful requests")
            return False
            
    except Exception as e:
        print(f"âŒ Performance test error: {e}")
        return False

async def main():
    """Main test function"""
    print("ğŸš€ DEPLOYMENT TEST")
    print("==================")
    print("Testing RAG + LLM Chatbot System deployment")
    print()
    
    test_results = []
    
    # Run tests
    test_results.append(await test_backend_health())
    test_results.append(await test_frontend_health())
    
    doc_id = await test_document_upload()
    if doc_id:
        test_results.append(await test_embedding_generation(doc_id))
    
    test_results.append(await test_chat_functionality())
    test_results.append(await test_streaming_chat())
    test_results.append(await test_system_stats())
    test_results.append(await test_offline_operation())
    test_results.append(await test_performance())
    
    # Cleanup
    if os.path.exists("test_document.txt"):
        os.remove("test_document.txt")
    
    # Summary
    print("\n" + "="*50)
    print("ğŸ“Š DEPLOYMENT TEST SUMMARY")
    print("="*50)
    
    passed = sum(test_results)
    total = len(test_results)
    
    print(f"Tests passed: {passed}/{total}")
    
    if passed == total:
        print("ğŸ‰ All tests passed! Deployment is successful.")
        print("âœ… System is ready for production use.")
    else:
        print("âš ï¸ Some tests failed. Please check the errors above.")
        print("âŒ System may not be ready for production use.")
    
    print("\nğŸŒ Access the system:")
    print("   Frontend: http://localhost")
    print("   Backend API: http://localhost:8000")
    print("   API Docs: http://localhost:8000/docs")

if __name__ == "__main__":
    asyncio.run(main())
